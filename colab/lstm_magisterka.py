# -*- coding: utf-8 -*-
"""LSTM_magisterka.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M3n_D18ZbHHRVtN4tDtijK7kbNOyOPMf
"""

import pandas as pd
import numpy as np
import random
import sys
sys.path.append('/content/drive/My Drive/Mgr_gas_transaction')
from dataset_config import *
from sklearn.preprocessing import MinMaxScaler, StandardScaler
# !pip install tensorflow==1.6
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization
tf.__version__

# Wczytanie danych
df = pd.read_csv("/content/drive/My Drive/Mgr_gas_transaction/tge_spot_preprocessed.csv",index_col=['TransactionDate'], parse_dates=['TransactionDate'])

# Przeskalowanie danych i podzia≈Ç na zbiory
# scaler = MinMaxScaler(feature_range=(0,1))
scaler = StandardScaler()
df_diff = df.pct_change().dropna()

df_scalled = pd.DataFrame(scaler.fit_transform(df_diff), index=df_diff.index, columns=['TGEgasDA'])
df_scalled.dropna(inplace=True)
df_scalled.head(10)

train_df = df_scalled[train_index[0] : val_index[0]][:-1]
test_df = df_scalled[test_index[0] : test_index[1]]
val_df = df_scalled[val_index[0]: val_index[1]]

train_df.shape, test_df.shape, val_df.shape, df.shape

TIME_WINDOW_LEN = 21
PRED_LEN = 1

def preprocesing_data(df, shuffle=True):
  sequential_data = []
  for idx in range(len(df) - TIME_WINDOW_LEN):
    sequential_data.append([np.array(df['TGEgasDA'].values[idx : idx+TIME_WINDOW_LEN]), df['TGEgasDA'].values[idx+TIME_WINDOW_LEN]])
  if shuffle:
    random.shuffle(sequential_data)
  X = []
  y = []
  for seq, target in sequential_data:  # going over our new sequential data
        X.append(seq)  # X is the sequences
        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)
  X = np.array(X)
  X = np.reshape(X, (X.shape[0], X.shape[1], 1))
  return X, np.array(y)

train_X, train_y = preprocesing_data(train_df)
val_X, val_y = preprocesing_data(val_df, shuffle=False)
test_X, test_y = preprocesing_data(test_df, shuffle=False)

train_X[1], train_y[1]

# Create model
EPOCHS = 40
BATCH_SIZE = 32

model = Sequential()
model.add(LSTM(64, input_shape=(train_X.shape[1:])))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))



model.add(Dense(1))

opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)

# Compile model
model.compile(
    loss='mean_absolute_error',
    optimizer=opt
)

model.fit(train_X, train_y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_X, val_y))

model.predict(train_X)[:10], train_y[:10]



# scaler.inverse_transform(train_y.reshape(-1,1))
# scaler.inverse_transform(model.predict(train_X))

data = scaler.inverse_transform(model.predict(val_X))
# df_true = df[train_index[0]: val_index[0]][:-1]
# df_true = df[test_index[0]: test_index[1]]
df_true = df[val_index[0]: val_index[1]]

df_true['pct_change'] = df_true['TGEgasDA'].pct_change()
df_true['TGEgasDA_shift'] = df_true['TGEgasDA'].shift()
df_true.dropna(inplace=True)
df_true = df_true[TIME_WINDOW_LEN:]
print(len(df_true))
print(len(data))
df_true['pred'] = data[1:]
df_true['TGEgasDA_pred'] = df_true['TGEgasDA_shift'] + df_true['TGEgasDA_shift'] * df_true['pred']
df_true[-30:]

mse(df_true['pct_change'], df_true['pred']) ** (1/2)

df_true[['pct_change','pred']].plot(figsize=(20,4))

mse(df_true['TGEgasDA'][1:],df_true['TGEgasDA_pred'].shift().dropna()) ** (1/2)

mse(df_true['TGEgasDA'],df_true['TGEgasDA_pred']) ** (1/2)

df_true[['TGEgasDA','TGEgasDA_pred']].plot(figsize=(20,4))



